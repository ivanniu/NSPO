# NSPO: Null-Space constrained Policy Optimization for Safety Alignment


This is the **official implementation** of the [**paper**](https://arxiv.org/abs/2512.11391):  
**"Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization"** (ICLR 2026)

---

## ğŸ’¡ Overview

Null-Space constrained Policy Optimization (NSPO) is a RL framework for LLM safety alignment while preserving their core abilities.  Notably, NSPO is data-efficient and only requires 40\% of public human-annotated safety data from PKU-SafeRLHF to achieve promising performance.

---

## ğŸ“‚ Project Structure

```
NSPO/
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ eval_sorrybench.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ evaluator_configs/
â”‚   â”‚   â”œâ”€â”€ configs.yaml
â”‚   â”‚   â””â”€â”€ template_base.txt
â”‚   â””â”€â”€ generate_alpaca.py
â”œâ”€â”€ script/
â”‚   â”œâ”€â”€ alpaca_eval.sh
â”‚   â”œâ”€â”€ livecodebench_eval.sh
â”‚   â”œâ”€â”€ math_eval.sh
â”‚   â”œâ”€â”€ merge_verl_ckpt.py
â”‚   â”œâ”€â”€ mmlu_bench.sh
â”‚   â”œâ”€â”€ safe_reward.py
â”‚   â”œâ”€â”€ safe_rl_verl_rule_base.sh
â”‚   â”œâ”€â”€ safety_eval.sh
â”‚   â”œâ”€â”€ start_vllm_llama_guard.sh
â”‚   â””â”€â”€ superGPQA_eval.sh
â””â”€â”€ verl/
```
---

## ğŸš€ Quick Start

### 1. Setup & Environment

**Download Assets:**
* **Base Model:** [Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)
* **Dataset:** [PKU-SafeRLHF](https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF)

**Installation:**
```bash
cd NSPO/verl
pip install -r requirements.txt
pip install .
```
### 2. Configuration
   - Modify `model_path` and `dataset_path` in:
     ```
     NSPO/verl/verl/workers/fsdp_workers.py (lines 248â€“249)
     ```
   - In the script directory, update `DATA_PATH` and `NSPO_PATH` in:
     ```
     NSPO/script/nspo_verl_rule_base.sh
     ```
   - In the script directory, update `MODEL_PATH` in:
     ```
     NSPO/script/start_vllm_llama_guard.sh
     ```

### 3. Launch Services and Training
   ```bash
   cd script
   bash start_vllm_llama_guard.sh
   bash nspo_verl_rule_base.sh
   ```

---

## ğŸ“Š Evaluation

The `script/` and `evaluation/` directories contain benchmark evaluation scripts.  
**Note:** You need to manually configure the dataset paths and API keys in these scripts before running them.

---

## ğŸ¤— Models & Checkpoints

We have released our trained checkpoint on Hugging Face:

* [Qwen2.5-7B-Instruct-NSPO](https://huggingface.co/ICLR2026NSPO/Qwen2.5-7B-Instruct-NSPO): The policy model fine-tuned using NSPO on the Qwen2.5-7B-Instruct.

---

## âœï¸ Citation

If you find this work helpful for your research, please cite our paper:
```
@article{niu2025mitigating,
  title={Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization},
  author={Niu, Yifan and Xiao, Han and Liu, Dongyi and Chen, Nuo and Li, Jia},
  journal={arXiv preprint arXiv:2512.11391},
  year={2025}
}
```
